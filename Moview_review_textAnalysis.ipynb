{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Anlysis on Movie review Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns a dictionary of all tokens (key=token and value=True)\n",
    "#In this format NaiveBayes expects the input\n",
    "def create_feature(word_list):\n",
    "    useful_words=[]\n",
    "    for token in word_list:\n",
    "        if token not in stopwords.words(\"english\"):\n",
    "            useful_words.append(token)  \n",
    "            \n",
    "    my_dict =dict([w,True] for w in useful_words)\n",
    "    return my_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': True, 'goes': True, 'market': True, 'mohan': True, 'school': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_feature([\"mohan\",\"am\",\"goes\",\"to\",\"market\",\"school\",\"goes\",\"I\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_words = []\n",
    "for f_id in movie_reviews.fileids('neg'):\n",
    "    words = movie_reviews.words(f_id)\n",
    "    dict4_each_file = create_feature(words)\n",
    "    neg_words.append((dict4_each_file,\"Bad\"))\n",
    "#print(len(neg_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_words = []\n",
    "for f_id in movie_reviews.fileids('pos'):\n",
    "    words = movie_reviews.words(f_id)\n",
    "    dict4_each_file = create_feature(words)\n",
    "    pos_words.append((dict4_each_file,\"Good\"))\n",
    "#print(pos_words[0])\n",
    "#print(len(pos_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Traning and testing data\n",
    "training_data = pos_words[:750]+neg_words[:750]\n",
    "testing_data = pos_words[750:]+neg_words[750:]\n",
    "#print(len(training_data),len(testing_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifer = NaiveBayesClassifier.train(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.39999999999999\n"
     ]
    }
   ],
   "source": [
    "accuracy = nltk.classify.util.accuracy(classifer,testing_data)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am abhijeet adhikary i do practice kill belongs kill from kishnaganj,blood donate my father is doctor fight and my mother is great\n",
      "my younger brothe is student\n"
     ]
    }
   ],
   "source": [
    "#User input text \n",
    "user_input = '''I am abhijeet adhikary i do practice on competitive programming, and i am happy to do that kill belongs kill from kishnaganj,blood donate my father is doctor fight and my mother is great\n",
    "my younger brothe is student'''\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = word_tokenize(user_input)\n",
    "featured_words = create_feature(words)\n",
    "classifer.classify(featured_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             magnificent = True             Good : Bad    =     15.0 : 1.0\n",
      "             outstanding = True             Good : Bad    =     13.6 : 1.0\n",
      "               insulting = True              Bad : Good   =     13.0 : 1.0\n",
      "              vulnerable = True             Good : Bad    =     12.3 : 1.0\n",
      "               ludicrous = True              Bad : Good   =     11.8 : 1.0\n",
      "                  avoids = True             Good : Bad    =     11.7 : 1.0\n",
      "             uninvolving = True              Bad : Good   =     11.7 : 1.0\n",
      "              astounding = True             Good : Bad    =     10.3 : 1.0\n",
      "             fascination = True             Good : Bad    =     10.3 : 1.0\n",
      "                 idiotic = True              Bad : Good   =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifer.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reads data from each file\n",
    "def add_data_from_files (file_list,data_list):\n",
    "    for f in file_list:\n",
    "        with open(f,'r') as fh:\n",
    "            data_list.append(fh.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiit\\AppData\\Roaming\\nltk_data\\corpora\\movie_reviews\\\n"
     ]
    }
   ],
   "source": [
    "directory = os.path.join(\"C:\\\\Users\\\\kiit\\\\AppData\\\\Roaming\\\\\",\"nltk_data\\\\corpora\\\\movie_reviews\\\\\")\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\kiit\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\movie_reviews\\\\pos', 'C:\\\\Users\\\\kiit\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\movie_reviews\\\\neg']\n"
     ]
    }
   ],
   "source": [
    "clses = [\"pos\",\"neg\"]\n",
    "# The data is in the data_dir, sorted into subdirectories, one for each class.\n",
    "data_dirs = [os.path.join(directory,cls) for cls in clses]\n",
    "print(data_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "training_proportion = (9,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,cls  in enumerate(clses):\n",
    "    d_dir = data_dirs[i]\n",
    "    #chnage directory\n",
    "    os.chdir(d_dir)\n",
    "    #all file inside d_dir\n",
    "    cls_files = os.listdir(d_dir)\n",
    "    #store total no. of files \n",
    "    num_cls_files = len(cls_files)\n",
    "    #start and end index of traning and testing data \n",
    "    training_index = (training_proportion[0] *(num_cls_files/training_proportion[1]))\n",
    "    \n",
    "    train_labels.extend(cls for f in cls_files[:int(training_index)])\n",
    "    test_labels.extend(cls for f in cls_files[int(training_index):])\n",
    "    \n",
    "    add_data_from_files (cls_files[:int(training_index)],train_data)\n",
    "    add_data_from_files (cls_files[int(training_index):],test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 37673)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = vectorizer.fit_transform(train_data)\n",
    "test_features = vectorizer.transform(test_data)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC(loss='squared_hinge', penalty=\"l2\",dual=False, tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train (or \"fit\") the model to the training data.\n",
    "clf.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the model on the test data.\n",
    "predicted_svm = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = clf.score(test_features,test_labels)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.5\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#user_input = \"I am abhijeet adhikary i do practice kill belongs kill from kishnaganj,blood donate my father is doctor fight and my mother is great my younger brothe is student\"\n",
    "#vectorizer1 = TfidfVectorizer(sublinear_tf=True, max_df=1,stop_words='english')\n",
    "#user_input_features = vectorizer1.fit_transform([user_input])\n",
    "#newlabels = clf.predict(user_input_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negih = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negih.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_knn = negih.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = negih.score(test_features,test_labels)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.0\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_dt = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n"
     ]
    }
   ],
   "source": [
    "acc = clf.score(test_features,test_labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 53, criterion = 'entropy', random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=53, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_rf = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = classifier.score(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.5\n"
     ]
    }
   ],
   "source": [
    "print(acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
