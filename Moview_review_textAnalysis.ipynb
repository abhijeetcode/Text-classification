{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all modules\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns a dictionary of all tokens (key=token and value=True)\n",
    "#In this format NaiveBayes expects the input\n",
    "def create_feature(word_list):\n",
    "    useful_words=[]\n",
    "    for token in word_list:\n",
    "        if token not in stopwords.words(\"english\"):\n",
    "            useful_words.append(token)  \n",
    "            \n",
    "    my_dict =dict([w,True] for w in useful_words)\n",
    "    return my_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': True, 'goes': True, 'market': True, 'mohan': True, 'school': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_feature([\"mohan\",\"am\",\"goes\",\"to\",\"market\",\"school\",\"goes\",\"I\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_words = []\n",
    "for f_id in movie_reviews.fileids('neg'):\n",
    "    words = movie_reviews.words(f_id)\n",
    "    dict4_each_file = create_feature(words)\n",
    "    neg_words.append((dict4_each_file,\"Bad\"))\n",
    "\n",
    "#print(len(neg_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(neg_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_words = []\n",
    "for f_id in movie_reviews.fileids('pos'):\n",
    "    words = movie_reviews.words(f_id)\n",
    "    dict4_each_file = create_feature(words)\n",
    "    pos_words.append((dict4_each_file,\"Good\"))\n",
    "#print(pos_words[0])\n",
    "#print(len(pos_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Traning and testing data\n",
    "training_data = pos_words[:750]+neg_words[:750]\n",
    "testing_data = pos_words[750:]+neg_words[750:]\n",
    "#print(len(training_data),len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifer = NaiveBayesClassifier.train(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.39999999999999\n"
     ]
    }
   ],
   "source": [
    "accuracy = nltk.classify.util.accuracy(classifer,testing_data)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am abhijeet adhikary i do practice kill belongs kill from kishnaganj,blood donate my father is doctor fight and my mother is great\n",
      "my younger brothe is student\n"
     ]
    }
   ],
   "source": [
    "#User input text \n",
    "user_input = '''I am abhijeet adhikary i do practice kill belongs kill from kishnaganj,blood donate my father is doctor fight and my mother is great\n",
    "my younger brothe is student'''\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = word_tokenize(user_input)\n",
    "featured_words = create_feature(words)\n",
    "classifer.classify(featured_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------SVM--------------SVM--------------SVM------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             magnificent = True             Good : Bad    =     15.0 : 1.0\n",
      "             outstanding = True             Good : Bad    =     13.6 : 1.0\n",
      "               insulting = True              Bad : Good   =     13.0 : 1.0\n",
      "              vulnerable = True             Good : Bad    =     12.3 : 1.0\n",
      "               ludicrous = True              Bad : Good   =     11.8 : 1.0\n",
      "             uninvolving = True              Bad : Good   =     11.7 : 1.0\n",
      "                  avoids = True             Good : Bad    =     11.7 : 1.0\n",
      "             fascination = True             Good : Bad    =     10.3 : 1.0\n",
      "              astounding = True             Good : Bad    =     10.3 : 1.0\n",
      "                 idiotic = True              Bad : Good   =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifer.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------------------SVM-------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reads data from each file\n",
    "def add_data_from_files (file_list,data_list):\n",
    "    for f in file_list:\n",
    "        with open(f,'r') as fh:\n",
    "            data_list.append(fh.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiit\\AppData\\Roaming\\nltk_data\\corpora\\movie_reviews\\\n"
     ]
    }
   ],
   "source": [
    "directory = os.path.join(\"C:\\\\Users\\\\kiit\\\\AppData\\\\Roaming\\\\\",\"nltk_data\\\\corpora\\\\movie_reviews\\\\\")\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\kiit\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\movie_reviews\\\\pos', 'C:\\\\Users\\\\kiit\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\movie_reviews\\\\neg']\n"
     ]
    }
   ],
   "source": [
    "clses = [\"pos\",\"neg\"]\n",
    "# The data is in the data_dir, sorted into subdirectories, one for each class.\n",
    "data_dirs = [os.path.join(directory,cls) for cls in clses]\n",
    "\n",
    "print(data_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "training_proportion = (9,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,cls  in enumerate(clses):\n",
    "    d_dir = data_dirs[i]\n",
    "    #chnage directory\n",
    "    os.chdir(d_dir)\n",
    "    #all file inside d_dir\n",
    "    cls_files = os.listdir(d_dir)\n",
    "    #store total no. of files \n",
    "    num_cls_files = len(cls_files)\n",
    "    #start and end index of traning and testing data \n",
    "    training_index = (training_proportion[0] *(num_cls_files/training_proportion[1]))\n",
    "    \n",
    "    train_labels.extend(cls for f in cls_files[:int(training_index)])\n",
    "    test_labels.extend(cls for f in cls_files[int(training_index):])\n",
    "    \n",
    "    add_data_from_files (cls_files[:int(training_index)],train_data)\n",
    "    add_data_from_files (cls_files[int(training_index):],test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 37673)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = vectorizer.fit_transform(train_data)\n",
    "test_features = vectorizer.transform(test_data)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(train_labels)\n",
    "#type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC(loss='squared_hinge', penalty=\"l2\",dual=False, tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train (or \"fit\") the model to the training data.\n",
    "clf.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the test data.\n",
    "predicted_labels = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg'\n",
      " 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos'\n",
      " 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos'\n",
      " 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg'\n",
      " 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos'\n",
      " 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos'\n",
      " 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos'\n",
      " 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos'\n",
      " 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos'\n",
      " 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg']\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = clf.score(test_features,test_labels)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.5\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_input = \"I am abhijeet adhikary i do practice kill belongs kill from kishnaganj,blood donate my father is doctor fight and my mother is great my younger brothe is student\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = TfidfVectorizer(sublinear_tf=True, max_df=1,stop_words='english')\n",
    "user_input_features = vectorizer1.fit_transform([user_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 16 features per sample; expecting 37673",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-fcf6feb35906>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnewlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_input_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \"\"\"\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 305\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 16 features per sample; expecting 37673"
     ]
    }
   ],
   "source": [
    "newlabels = clf.predict(user_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
